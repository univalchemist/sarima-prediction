{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339ed3c-1cf2-4807-9e92-64ab1f36f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cudf\n",
    "from cuml.tsa.arima import ARIMA\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from itertools import product\n",
    "import warnings\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "import datetime\n",
    "from ast import literal_eval\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# n-step sarima forecast\n",
    "def sarima_forecast(history, config, n_test):\n",
    "\torder, sorder = config\n",
    "\t# define model\n",
    "\tmodel = ARIMA(history, order=order, seasonal_order=sorder, fit_intercept=False)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit()\n",
    "\t# make n step forecast\n",
    "\t# predict = model_fit.predict(start=len(history), end=len(history) + n_test - 1, dynamic=True)\n",
    "\tfcast = model_fit.forecast(n_test)\n",
    "    # forecast = model_fit.get_forecast(steps=n_test)\n",
    "\treturn fcast\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    " \n",
    "# forward validation for univariate data\n",
    "def forward_validation(data, n_test, cfg):\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model and predict n step\n",
    "    fcast = sarima_forecast(train, cfg, n_test)\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, fcast)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "\t# convert config to a key\n",
    "    key = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "\t# check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > Model[%s] %.5f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "\t    # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "\t    scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a set of sarima configs to try\n",
    "def sarima_configs():\n",
    "    models = list()\n",
    "\t# define config lists\n",
    "    p_params = range(1, 3)\n",
    "    d_params = range(0, 2)\n",
    "    q_params = range(1, 3)\n",
    "    P_params = range(1, 3)\n",
    "    D_params = range(0, 2)\n",
    "    Q_params = range(1, 3)\n",
    "    m_params = [30, 40, 50, 60, 70]\n",
    "    # m_params = [30]\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for P in P_params:\n",
    "                    for D in D_params:\n",
    "                        for Q in Q_params:\n",
    "                            for m in m_params:\n",
    "                                cfg = [(p,d,q), (P,D,Q,m)]\n",
    "                                models.append(cfg)\n",
    "    return models\n",
    "def cal_duration(time1, time2):\n",
    "    td = time2 - time1\n",
    "    return td.total_seconds()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    df = pd.read_csv('eurusd_h1_2016_1_2021_10.csv')\n",
    "    df= pd.DataFrame(df,columns = ['Close'])\n",
    "\n",
    "    #Calculate the natural logarithm of the data so that the first difference \n",
    "    #gets the data percentage growth.\n",
    "    df = np.log(df)\n",
    "    # for i in range(2, 50):\n",
    "    i = 1\n",
    "    n_test = 24\n",
    "    # all_data = df[i * n_test:( i * n_test) + 3000]\n",
    "    all_data = df[-300:]\n",
    "    data = all_data[:-n_test] # For test of prediction last predict_step steps\n",
    "\n",
    "    # model configs\n",
    "    cfg_list = sarima_configs()\n",
    "    print(f'config list is {len(cfg_list)}')\n",
    "    time1 = datetime.datetime.now()\n",
    "\n",
    "    # grid search\n",
    "    scores = grid_search(data, cfg_list, n_test) # [('[(1, 1, 2), (2, 1, 2, 70)]', 0.0019030947019740227), ('[(2, 1, 1), (2, 1, 2, 70)]', 0.001963385101989825)]\n",
    "    time2 = datetime.datetime.now()\n",
    "    td = time2 - time1\n",
    "    print('----------grid search duration-------------')\n",
    "    print(td.total_seconds())\n",
    "\n",
    "    # list top 3 configs\n",
    "    for cfg, error in scores[:3]:\n",
    "        print(cfg, error)\n",
    "    \n",
    "    # extract the first element with the lowest mse and convert string of array to array\n",
    "    first_element = scores[0][0]\n",
    "    first_element = literal_eval(first_element)\n",
    "\n",
    "    # order and seasonal order\n",
    "    order = first_element[0]\n",
    "    s_order = first_element[1]\n",
    "    print('------------optimized params-----------')\n",
    "    print(order)\n",
    "    print(s_order)\n",
    "    # order = (2, 1, 2)\n",
    "    # s_order = (2, 1, 2, 60)\n",
    "    time1 = datetime.datetime.now()\n",
    "\n",
    "    # Build Model to test the result with the data_test\n",
    "    model_fit = ARIMA(data, order=order, seasonal_order=s_order).fit()\n",
    "\n",
    "    prediction = model_fit.forecast(n_test)\n",
    "\n",
    "    # data=np.exp(data)\n",
    "    actual=np.exp(all_data[-n_test:len(all_data)])\n",
    "    prediction= np.exp(prediction)\n",
    "    time2 = datetime.datetime.now()\n",
    "    print('------------duration-----------')\n",
    "    print(cal_duration(time1, time2))\n",
    "\n",
    "    #Plot prediction n steps ahead\n",
    "    plt.plot(actual, label='actual')\n",
    "    plt.plot(prediction, label='prediction')\n",
    "    plt.title('Prediction vs Actual')\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.savefig('{}test.png'.format(i))\n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bcec4-c036-4649-825d-309a8895e08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a18e21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
